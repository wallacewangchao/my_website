<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>project icps</title>

  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../css/sub-page.css">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-QZ8WNGYXYL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-QZ8WNGYXYL');
  </script>

</head>
<body>
  <main>
    <h1>
        Investigating Explainable Human-Robot Interaction with Augmented Reality
    </h1>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/c7vojX7NJjg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <p>
      In learning by demonstration with social robots, fluid and coordinated interaction between human teacher and robotic learner is particularly critical and yet often difficult to assess. This is even more so if robots are to learn from non-expert users. In such cases, it is sometimes troublesome for the teacher to get a grasp of what the robot knows or to assess if a correct representation of the task has been formed even before the robot demonstrates it back. Here, we introduce a new feedback modality making use of Augmented Reality to visualize the perceptual beliefs of the robot in an interactive way. Such cues are indeed overlaid directly on the shared workspace, as perceived by the teacher, without the need for an explicit inquiry.
    </p>

    <h2>
      Story board
    </h2>
    <img src="../img/subpages/ar-robot/Storyboard.png">

    <h2>
      Design of the AR interface
    </h2>
    <img src="../img/subpages/ar-robot/design.jpg">

    <h2>
      System structure
    </h2>
    <img src="../img/subpages/ar-robot/Sys_architecture.png">

    <h2>
      Publications:
    </h2>
    <a href="https://openreview.net/pdf?id=S2zeAWt4hk5" target="_blank">
      Chao Wang, Anna Belardinelli (2022, March). Investigating explainable human-robot interaction with augmented reality. In VAM workshop of the 2022 ACM/IEEE International Conference on Human-Robot Interaction.
    </a>

  </main>

</body>
</html>